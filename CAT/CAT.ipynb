{"cells":[{"cell_type":"markdown","metadata":{"id":"f260223a"},"source":["<a id=\"section-one\"></a>\n","## 1 Import Libraries and download data"],"id":"f260223a"},{"cell_type":"markdown","metadata":{"id":"dd9d1294"},"source":["<a id=\"define-device\"></a>\n","### 1.2 Define device"],"id":"dd9d1294"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19526,"status":"ok","timestamp":1682480338453,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"},"user_tz":240},"id":"FqEDEQQJpwtB","outputId":"1808f382-c2b7-4b60-fe7e-fbbbe1e4d672"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"FqEDEQQJpwtB"},{"cell_type":"markdown","source":["#OE 2 unbalanced labels"],"metadata":{"id":"dgKhIfA6koN3"},"id":"dgKhIfA6koN3"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,1)\n","\n","  return data\n","\n","\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=1\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=1\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=1\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:1045]\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:300]\n","frames = [Data_0, Data_2]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:772]\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:200]\n","frames = [Data_0, Data_2]\n","Final_Data_S2 = pd.concat(frames)\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[200:,:]\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[150:,:]\n","Target_test = Final_Data_S2.iloc[:150,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/CAT/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/CAT/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/CAT/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/CAT/data/Target_test.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaAL6_V_kn1J","executionInfo":{"status":"ok","timestamp":1682482447348,"user_tz":240,"elapsed":3820,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"acc44bba-729c-4af0-b4fc-7e267f84d46d"},"id":"oaAL6_V_kn1J","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n"]}]},{"cell_type":"markdown","source":["#OE 3 unbalanced labels"],"metadata":{"id":"H5kJaPJNi3uc"},"id":"H5kJaPJNi3uc"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,2)\n","\n","  return data\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=2\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=2\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=2\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=2\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:1045]\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:300]\n","Data_3 = Final_Data_S1[Final_Data_S1.labels == 2].iloc[:300]\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:772]\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:200]\n","Data_3 = Final_Data_S2[Final_Data_S2.labels == 2].iloc[:200]\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S2 = pd.concat(frames)\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[200:,:]\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[150:,:]\n","Target_test = Final_Data_S2.iloc[:150,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/CAT/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/CAT/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/CAT/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/CAT/data/Target_test.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6s34COBi3MM","executionInfo":{"status":"ok","timestamp":1682481534365,"user_tz":240,"elapsed":5160,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"81fdf1d1-b431-495a-8a26-c77b5208a914"},"id":"Y6s34COBi3MM","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n"]}]},{"cell_type":"markdown","source":["#OE balanced 2 labels"],"metadata":{"id":"iHUKkTdKkJP2"},"id":"iHUKkTdKkJP2"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,1)\n","\n","  return data\n","\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=1\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=1\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=1\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[500:,:]\n","Source_test = Final_Data_S1.iloc[:500,:]\n","\n","Target_train = Final_Data_S2.iloc[500:,:]\n","Target_test = Final_Data_S2.iloc[:500,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/CAT/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/CAT/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/CAT/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/CAT/data/Target_test.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qm7aAMUikGkX","executionInfo":{"status":"ok","timestamp":1682482754830,"user_tz":240,"elapsed":5214,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"5d8d0fc0-88c6-4eb8-dfe2-85f9f38cd3f4"},"id":"qm7aAMUikGkX","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n"]}]},{"cell_type":"markdown","metadata":{"id":"t_6Ru51m_deH"},"source":["#OE 3 labels balanced"],"id":"t_6Ru51m_deH"},{"cell_type":"code","execution_count":22,"metadata":{"id":"La67l8Ng-xmm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682481993215,"user_tz":240,"elapsed":8124,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"5495334e-0941-47d4-d08d-af18455eba47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,2)\n","\n","  return data\n","\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=2\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=2\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=2\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=2\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[500:,:]\n","Source_test = Final_Data_S1.iloc[:500,:]\n","\n","Target_train = Final_Data_S2.iloc[500:,:]\n","Target_test = Final_Data_S2.iloc[:500,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/CAT/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/CAT/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/CAT/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/CAT/data/Target_test.csv', index=False)"],"id":"La67l8Ng-xmm"},{"cell_type":"markdown","metadata":{"id":"aW1uEd59_iOv"},"source":["#Load Data AR: 3 Activities"],"id":"aW1uEd59_iOv"},{"cell_type":"code","execution_count":10,"metadata":{"id":"wyaalwUr-65K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682481146954,"user_tz":240,"elapsed":6517,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"ed9f6c73-3f82-4ce5-bba7-2d708d9ce3ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n"]}],"source":["import pandas as pd \n","import numpy as np\n","np.random.seed(2021)\n","!wget http://casas.wsu.edu/datasets/hh101.zip\n","!wget http://casas.wsu.edu/datasets/hh105.zip\n","!unzip '/content/hh105.zip'\n","!unzip /content/hh101.zip\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,2)\n","  return data\n","\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE\n","\n","Final_Data_S1 = pd.read_csv(\"/content/hh101/hh101.ann.features.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/hh105/hh105.ann.features.csv\")\n","Final_Data_S1.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","Final_Data_S2.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","\n","Final_Data_S1 = Final_Data_S1.drop(['lastSensorEventHours', 'lastSensorEventSeconds', 'lastSensorDayOfWeek','lastSensorID'], axis= 1)\n","Final_Data_S2 = Final_Data_S2.drop(['lastSensorEventHours', 'lastSensorEventSeconds','lastSensorDayOfWeek', 'lastSensorID'], axis= 1)\n","\n","Final_Data_S1 = Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Breakfast',  'Watch_TV', 'Toilet' ])]\n","Final_Data_S2 = Final_Data_S2[Final_Data_S2.labels.isin([ 'Cook_Breakfast',  'Watch_TV', 'Toilet' ])]\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Toilet'])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Breakfast'])].index,'labels']=2\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Toilet'])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Breakfast'])].index,'labels']=2\n","\n","\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:2000]#2000#4000\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:2000]#2000\n","Data_3 = Final_Data_S1[Final_Data_S1.labels == 2].iloc[:2000]#2000\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:1000]#1000#2000\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:1000]#1000\n","Data_3 = Final_Data_S2[Final_Data_S2.labels == 2].iloc[:1000]#1000\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S2 = pd.concat(frames)\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","\n","Source_train = Final_Data_S1.iloc[200:,:]#1000\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[150:,:]#500\n","Target_test = Final_Data_S2.iloc[:150,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/CAT/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/CAT/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/CAT/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/CAT/data/Target_test.csv', index=False)\n"],"id":"wyaalwUr-65K"},{"cell_type":"markdown","metadata":{"id":"hRCYevEuAB4A"},"source":["#Load Data AR: 5 Activities"],"id":"hRCYevEuAB4A"},{"cell_type":"code","execution_count":null,"metadata":{"id":"01hqvUJ9AGiO"},"outputs":[],"source":["import pandas as pd \n","import numpy as np\n","import random\n","np.random.seed(2021)\n","!wget http://casas.wsu.edu/datasets/hh101.zip\n","!wget http://casas.wsu.edu/datasets/hh105.zip\n","!unzip '/content/hh105.zip'\n","!unzip /content/hh101.zip\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,4)\n","  return data\n","\n","Final_Data_S1 = pd.read_csv(\"/content/hh101/hh101.ann.features.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/hh105/hh105.ann.features.csv\")\n","Final_Data_S1.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","Final_Data_S2.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","\n","Final_Data_S1 = Final_Data_S1.drop(['lastSensorEventHours', 'lastSensorEventSeconds', 'lastSensorDayOfWeek','lastSensorID'], axis= 1)\n","Final_Data_S2 = Final_Data_S2.drop(['lastSensorEventHours', 'lastSensorEventSeconds','lastSensorDayOfWeek', 'lastSensorID'], axis= 1)\n","\n","Final_Data_S1 = Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Dinner', 'Cook_Breakfast', 'Cook_Lunch', 'Watch_TV', 'Toilet' ])]\n","Final_Data_S2 = Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Dinner', 'Cook_Breakfast', 'Cook_Lunch', 'Watch_TV', 'Toilet' ])]\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Lunch'])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Toilet'])].index,'labels']=2\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Breakfast'])].index,'labels']=3\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Dinner'])].index,'labels']=4\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Lunch'])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Toilet'])].index,'labels']=2\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Breakfast'])].index,'labels']=3\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Dinner'])].index,'labels']=4\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:4000]#2000#4000\n","Data_1 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:4000]#4000\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 2].iloc[:2000]#2000\n","Data_3 = Final_Data_S1[Final_Data_S1.labels == 3].iloc[:4000]#4000\n","Data_4 = Final_Data_S1[Final_Data_S1.labels == 4].iloc[:2000]#\n","frames = [Data_0, Data_1, Data_2, Data_3, Data_4]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:2000]#1000#2000\n","Data_1 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:2000]#2000\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 2].iloc[:1000]#\n","Data_3 = Final_Data_S2[Final_Data_S2.labels == 3].iloc[:2000]#2000\n","Data_4 = Final_Data_S2[Final_Data_S2.labels == 4].iloc[:1000]#\n","frames = [Data_0, Data_1, Data_2, Data_3, Data_4]\n","Final_Data_S2 = pd.concat(frames)\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[200:,:]#1000#\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[150:,:]#500#\n","Target_test = Final_Data_S2.iloc[:150,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/CAT/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/CAT/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/CAT/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/CAT/data/Target_test.csv', index=False)"],"id":"01hqvUJ9AGiO"},{"cell_type":"code","source":["!pip install --upgrade tf_slim\n","import tf_slim as slim"],"metadata":{"id":"KARGbXz8cydC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682480596646,"user_tz":240,"elapsed":6115,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"968b2bfd-2671-4603-ca59-5f29baad3a39"},"id":"KARGbXz8cydC","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tf_slim in /usr/local/lib/python3.9/dist-packages (1.1.0)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from tf_slim) (1.4.0)\n"]}]},{"cell_type":"code","execution_count":33,"metadata":{"id":"rB2HRmYbE8G3","executionInfo":{"status":"ok","timestamp":1682482801585,"user_tz":240,"elapsed":392,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}}},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/CAT')"],"id":"rB2HRmYbE8G3"},{"cell_type":"code","execution_count":35,"metadata":{"id":"7HLpsyW2_Pb4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ed66411-0cb7-4889-fc28-cc6b68b0e2c0","executionInfo":{"status":"ok","timestamp":1682482942507,"user_tz":240,"elapsed":75860,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-26 04:21:09.037403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","W0426 04:21:11.721268 140511851284288 deprecation.py:364] From /usr/local/lib/python3.9/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","/usr/local/lib/python3.9/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n","  warnings.warn('`tf.layers.flatten` is deprecated and '\n","/usr/local/lib/python3.9/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0426 04:21:11.810507 140511851284288 deprecation.py:364] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0426 04:21:12.094983 140511851284288 deprecation.py:364] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","['fc8', 'fc7', 'fc6', 'conv5', 'conv4', 'conv3', 'conv2', 'conv1']\n","==============new_weights=======================\n","[<tf.Variable 'reuse_inference/conv1/weights:0' shape=(1, 9, 20) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/gamma:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/weights:0' shape=(1, 20, 50) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/gamma:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/fc1/weights:0' shape=(50, 100) dtype=float32>, <tf.Variable 'reuse_inference/fc2/weights:0' shape=(100, 2) dtype=float32>]\n","==============new_biases=======================\n","[<tf.Variable 'reuse_inference/conv1/biases:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/beta:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/biases:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/beta:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/fc1/biases:0' shape=(100,) dtype=float32>, <tf.Variable 'reuse_inference/fc2/biases:0' shape=(2,) dtype=float32>]\n","+++++++++++++++ batch norm update ops +++++++++++++++++\n","[<tf.Operation 'reuse_inference/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>]\n","=================Discriminator_weights=====================\n","[<tf.Variable 'reuse/D/weights:0' shape=(2, 500) dtype=float32>, <tf.Variable 'reuse/D/weights2:0' shape=(500, 500) dtype=float32>, <tf.Variable 'reuse/D/weights3:0' shape=(500, 1) dtype=float32>]\n","=================Discriminator_biases=====================\n","[<tf.Variable 'reuse/D/biases:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/biases2:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/biases3:0' shape=(1,) dtype=float32>]\n","INFO:tensorflow:Summary name Training Accuracy is illegal; using Training_Accuracy instead.\n","I0426 04:21:14.594897 140511851284288 summary_op_util.py:61] Summary name Training Accuracy is illegal; using Training_Accuracy instead.\n","INFO:tensorflow:Summary name Testing Accuracy is illegal; using Testing_Accuracy instead.\n","I0426 04:21:14.596145 140511851284288 summary_op_util.py:61] Summary name Testing Accuracy is illegal; using Testing_Accuracy instead.\n","============================GLOBAL TRAINABLE VARIABLES ============================\n","[<tf.Variable 'reuse_inference/conv1/weights:0' shape=(1, 9, 20) dtype=float32>, <tf.Variable 'reuse_inference/conv1/biases:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/gamma:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/beta:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/weights:0' shape=(1, 20, 50) dtype=float32>, <tf.Variable 'reuse_inference/conv2/biases:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/gamma:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/beta:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/fc1/weights:0' shape=(50, 100) dtype=float32>, <tf.Variable 'reuse_inference/fc1/biases:0' shape=(100,) dtype=float32>, <tf.Variable 'reuse_inference/fc2/weights:0' shape=(100, 2) dtype=float32>, <tf.Variable 'reuse_inference/fc2/biases:0' shape=(2,) dtype=float32>, <tf.Variable 'reuse/D/weights:0' shape=(2, 500) dtype=float32>, <tf.Variable 'reuse/D/biases:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/weights2:0' shape=(500, 500) dtype=float32>, <tf.Variable 'reuse/D/biases2:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/weights3:0' shape=(500, 1) dtype=float32>, <tf.Variable 'reuse/D/biases3:0' shape=(1,) dtype=float32>]\n","2023-04-26 04:21:15.967169: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-04-26 04:21:16.570724 Start training...\n","Epoch 0.34550907306825873 time 7.288947343826294s Step 250 lambda 0.0312 lamb2 0.0000 rate 0.0100 C_loss 0.4354 G_loss -0.1366 D_loss 0.1366 SNTG_loss 27.2791 chose_rate 1.0000\n","Validation Accuracy = 0.8780 Max_Accuracy = 0.8780\n","Validation F1score = 0.8656 Max_f1score = 0.8656\n","Epoch 0.6910181461365175 time 3.1927359104156494s Step 500 lambda 0.0624 lamb2 0.0000 rate 0.0100 C_loss 0.3520 G_loss -0.1386 D_loss 0.1386 SNTG_loss 27.4528 chose_rate 1.0000\n","Validation Accuracy = 0.5500 Max_Accuracy = 0.8780\n","Validation F1score = 0.6570 Max_f1score = 0.8656\n","Epoch 1.0365272192047763 time 4.7893571853637695s Step 750 lambda 0.0935 lamb2 0.0000 rate 0.0100 C_loss 0.3833 G_loss -0.1380 D_loss 0.1380 SNTG_loss 24.8156 chose_rate 1.0000\n","Validation Accuracy = 0.8700 Max_Accuracy = 0.8780\n","Validation F1score = 0.8546 Max_f1score = 0.8656\n","Epoch 1.382036292273035 time 4.72240138053894s Step 1000 lambda 0.1244 lamb2 0.0000 rate 0.0100 C_loss 0.3456 G_loss -0.1416 D_loss 0.1416 SNTG_loss 24.8733 chose_rate 1.0000\n","Validation Accuracy = 0.8620 Max_Accuracy = 0.8780\n","Validation F1score = 0.8441 Max_f1score = 0.8656\n","Epoch 1.7275453653412938 time 3.234480619430542s Step 1250 lambda 0.1550 lamb2 0.0000 rate 0.0100 C_loss 0.3629 G_loss -0.1333 D_loss 0.1333 SNTG_loss 26.3310 chose_rate 1.0000\n","Validation Accuracy = 0.8820 Max_Accuracy = 0.8820\n","Validation F1score = 0.8693 Max_f1score = 0.8693\n","Epoch 2.0730544384095526 time 3.2367336750030518s Step 1500 lambda 0.1853 lamb2 0.0000 rate 0.0100 C_loss 0.3910 G_loss -0.1307 D_loss 0.1307 SNTG_loss 20.9496 chose_rate 1.0000\n","Validation Accuracy = 0.8840 Max_Accuracy = 0.8840\n","Validation F1score = 0.8711 Max_f1score = 0.8711\n","Epoch 2.4185635114778115 time 3.891148328781128s Step 1750 lambda 0.2153 lamb2 0.0000 rate 0.0100 C_loss 0.2884 G_loss -0.1404 D_loss 0.1404 SNTG_loss 23.5334 chose_rate 1.0000\n","Validation Accuracy = 0.8880 Max_Accuracy = 0.8880\n","Validation F1score = 0.8769 Max_f1score = 0.8769\n","Epoch 2.76407258454607 time 4.192991495132446s Step 2000 lambda 0.2449 lamb2 0.0000 rate 0.0100 C_loss 0.2849 G_loss -0.1346 D_loss 0.1346 SNTG_loss 22.9854 chose_rate 1.0000\n","Validation Accuracy = 0.8720 Max_Accuracy = 0.8880\n","Validation F1score = 0.8566 Max_f1score = 0.8769\n","Epoch 3.1095816576143287 time 3.205056667327881s Step 2250 lambda 0.2741 lamb2 0.0000 rate 0.0100 C_loss 0.2267 G_loss -0.1423 D_loss 0.1423 SNTG_loss 18.9835 chose_rate 1.0000\n","Validation Accuracy = 0.8760 Max_Accuracy = 0.8880\n","Validation F1score = 0.8615 Max_f1score = 0.8769\n","Epoch 3.4550907306825875 time 3.2282567024230957s Step 2500 lambda 0.3027 lamb2 0.0000 rate 0.0100 C_loss 0.3501 G_loss -0.1360 D_loss 0.1360 SNTG_loss 23.3761 chose_rate 1.0000\n","Validation Accuracy = 0.8740 Max_Accuracy = 0.8880\n","Validation F1score = 0.8597 Max_f1score = 0.8769\n","Epoch 3.8005998037508464 time 4.321333885192871s Step 2750 lambda 0.3308 lamb2 0.0000 rate 0.0100 C_loss 0.4307 G_loss -0.1433 D_loss 0.1433 SNTG_loss 26.4173 chose_rate 1.0000\n","Validation Accuracy = 0.8420 Max_Accuracy = 0.8880\n","Validation F1score = 0.8162 Max_f1score = 0.8769\n","Epoch 4.146108876819105 time 3.2291131019592285s Step 3000 lambda 0.3584 lamb2 0.0000 rate 0.0100 C_loss 0.4257 G_loss -0.1382 D_loss 0.1382 SNTG_loss 24.5417 chose_rate 1.0000\n","Validation Accuracy = 0.8800 Max_Accuracy = 0.8880\n","Validation F1score = 0.8666 Max_f1score = 0.8769\n","Epoch 4.491617949887364 time 3.1287882328033447s Step 3250 lambda 0.3853 lamb2 0.0000 rate 0.0100 C_loss 0.2942 G_loss -0.1327 D_loss 0.1327 SNTG_loss 23.5514 chose_rate 1.0000\n","Validation Accuracy = 0.8840 Max_Accuracy = 0.8880\n","Validation F1score = 0.8715 Max_f1score = 0.8769\n","Epoch 4.837127022955623 time 3.1730008125305176s Step 3500 lambda 0.4116 lamb2 0.0000 rate 0.0100 C_loss 0.2896 G_loss -0.1367 D_loss 0.1367 SNTG_loss 20.3561 chose_rate 1.0000\n","Validation Accuracy = 0.8600 Max_Accuracy = 0.8880\n","Validation F1score = 0.8302 Max_f1score = 0.8769\n","Epoch 5.182636096023881 time 4.45927882194519s Step 3750 lambda 0.4372 lamb2 0.0000 rate 0.0100 C_loss 0.5452 G_loss -0.1327 D_loss 0.1327 SNTG_loss 24.6362 chose_rate 1.0000\n","Validation Accuracy = 0.8480 Max_Accuracy = 0.8880\n","Validation F1score = 0.8124 Max_f1score = 0.8769\n","Epoch 5.52814516909214 time 3.188957452774048s Step 4000 lambda 0.4621 lamb2 0.0000 rate 0.0100 C_loss 0.2604 G_loss -0.1344 D_loss 0.1344 SNTG_loss 23.8482 chose_rate 1.0000\n","Validation Accuracy = 0.8120 Max_Accuracy = 0.8880\n","Validation F1score = 0.7605 Max_f1score = 0.8769\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/CAT/train.py\", line 305, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/MyDrive/CAT/train.py\", line 220, in main\n","    summary,_,closs,gloss,dloss,sn_loss, chose_rate_=sess.run([merged,optimizer,model.loss,model.G_loss,model.D_loss,model.sntg_loss, model.chose_rate], feed_dict={x_s: batch_xs,x_t: Tbatch_xs,decay_learning_rate:rate,adlamb:lamb,y: batch_ys,yt:Tbatch_ys,sntglamb:lamb2})\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 968, in run\n","    result = self._run(None, fetches, feed_dict, options_ptr,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1191, in _run\n","    results = self._do_run(handle, final_targets, final_fetches,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1371, in _do_run\n","    return self._do_call(_run_fn, feeds, fetches, targets, options,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1378, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1361, in _run_fn\n","    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1454, in _call_tf_sessionrun\n","    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n","KeyboardInterrupt\n","^C\n"]}],"source":["!python train.py --source usps --target mnist --revgrad 1"],"id":"7HLpsyW2_Pb4"},{"cell_type":"code","source":["!python train_r.py --source usps --target mnist"],"metadata":{"id":"pEz6Uox0U8J_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682483031561,"user_tz":240,"elapsed":84295,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"472cb92a-b9f1-4c14-a189-616f75101c61"},"id":"pEz6Uox0U8J_","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-26 04:22:28.963279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[653, 5642, 2294, 6465, 3921, 2005, 3494, 4323, 4849, 1939] [34046, 2951, 5692, 4582, 4401, 40635, 37615, 29280, 44222, 49101]\n","1590\n","1044\n","500\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","W0426 04:22:31.622235 140253840336704 deprecation.py:364] From /usr/local/lib/python3.9/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","/usr/local/lib/python3.9/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n","  warnings.warn('`tf.layers.flatten` is deprecated and '\n","/usr/local/lib/python3.9/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W0426 04:22:31.721122 140253840336704 deprecation.py:364] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0426 04:22:32.024096 140253840336704 deprecation.py:364] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","['fc8', 'fc7', 'fc6', 'conv5', 'conv4', 'conv3', 'conv2', 'conv1']\n","==============new_weights=======================\n","[<tf.Variable 'reuse_inference/conv1/weights:0' shape=(1, 9, 20) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/gamma:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/weights:0' shape=(1, 20, 50) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/gamma:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/fc1/weights:0' shape=(50, 100) dtype=float32>, <tf.Variable 'reuse_inference/fc2/weights:0' shape=(100, 2) dtype=float32>]\n","==============new_biases=======================\n","[<tf.Variable 'reuse_inference/conv1/biases:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/beta:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/biases:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/beta:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/fc1/biases:0' shape=(100,) dtype=float32>, <tf.Variable 'reuse_inference/fc2/biases:0' shape=(2,) dtype=float32>]\n","+++++++++++++++ batch norm update ops +++++++++++++++++\n","[<tf.Operation 'reuse_inference/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_1/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_2/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv1/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv1/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv2/BatchNorm/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>, <tf.Operation 'reuse_inference_3/conv2/BatchNorm/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>]\n","=================Discriminator_weights=====================\n","[<tf.Variable 'reuse/D/weights:0' shape=(2, 500) dtype=float32>, <tf.Variable 'reuse/D/weights2:0' shape=(500, 500) dtype=float32>, <tf.Variable 'reuse/D/weights3:0' shape=(500, 1) dtype=float32>]\n","=================Discriminator_biases=====================\n","[<tf.Variable 'reuse/D/biases:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/biases2:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/biases3:0' shape=(1,) dtype=float32>]\n","INFO:tensorflow:Summary name Training Accuracy is illegal; using Training_Accuracy instead.\n","I0426 04:22:34.087540 140253840336704 summary_op_util.py:61] Summary name Training Accuracy is illegal; using Training_Accuracy instead.\n","INFO:tensorflow:Summary name Testing Accuracy is illegal; using Testing_Accuracy instead.\n","I0426 04:22:34.088553 140253840336704 summary_op_util.py:61] Summary name Testing Accuracy is illegal; using Testing_Accuracy instead.\n","============================GLOBAL TRAINABLE VARIABLES ============================\n","[<tf.Variable 'reuse_inference/conv1/weights:0' shape=(1, 9, 20) dtype=float32>, <tf.Variable 'reuse_inference/conv1/biases:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/gamma:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv1/BatchNorm/beta:0' shape=(20,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/weights:0' shape=(1, 20, 50) dtype=float32>, <tf.Variable 'reuse_inference/conv2/biases:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/gamma:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/conv2/BatchNorm/beta:0' shape=(50,) dtype=float32>, <tf.Variable 'reuse_inference/fc1/weights:0' shape=(50, 100) dtype=float32>, <tf.Variable 'reuse_inference/fc1/biases:0' shape=(100,) dtype=float32>, <tf.Variable 'reuse_inference/fc2/weights:0' shape=(100, 2) dtype=float32>, <tf.Variable 'reuse_inference/fc2/biases:0' shape=(2,) dtype=float32>, <tf.Variable 'reuse/D/weights:0' shape=(2, 500) dtype=float32>, <tf.Variable 'reuse/D/biases:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/weights2:0' shape=(500, 500) dtype=float32>, <tf.Variable 'reuse/D/biases2:0' shape=(500,) dtype=float32>, <tf.Variable 'reuse/D/weights3:0' shape=(500, 1) dtype=float32>, <tf.Variable 'reuse/D/biases3:0' shape=(1,) dtype=float32>]\n","2023-04-26 04:22:35.140094: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-04-26 04:22:35.404827 Start training...\n","Epoch 0.34550907306825873 time 7.344604969024658s Step 250 lambda 0.0312 lamb2 0.0000 rate 0.0100 C_loss 0.5854 G_loss -0.1117 D_loss 0.1117 SNTG_loss 26.7840 chose_rate 0.3125\n","Validation Accuracy = 0.8625 Max_Accuracy = 0.8625\n","Validation F1score = 0.8430 Max_f1score = 0.8430\n","Epoch 0.6910181461365175 time 3.177511692047119s Step 500 lambda 0.0624 lamb2 0.0000 rate 0.0100 C_loss 0.3867 G_loss -0.1300 D_loss 0.1300 SNTG_loss 26.6889 chose_rate 0.1875\n","Validation Accuracy = 0.8775 Max_Accuracy = 0.8775\n","Validation F1score = 0.8611 Max_f1score = 0.8611\n","Epoch 1.0365272192047763 time 3.2517383098602295s Step 750 lambda 0.0935 lamb2 0.0000 rate 0.0100 C_loss 0.2154 G_loss nan D_loss nan SNTG_loss 26.4297 chose_rate 0.0000\n","Validation Accuracy = 0.8925 Max_Accuracy = 0.8925\n","Validation F1score = 0.8809 Max_f1score = 0.8809\n","Epoch 1.382036292273035 time 4.015483140945435s Step 1000 lambda 0.1244 lamb2 0.0000 rate 0.0100 C_loss 0.3319 G_loss -0.1794 D_loss 0.1794 SNTG_loss 26.2656 chose_rate 0.3750\n","Validation Accuracy = 0.8950 Max_Accuracy = 0.8950\n","Validation F1score = 0.8829 Max_f1score = 0.8829\n","Epoch 1.7275453653412938 time 3.0872230529785156s Step 1250 lambda 0.1550 lamb2 0.0000 rate 0.0100 C_loss 0.3494 G_loss -0.1401 D_loss 0.1401 SNTG_loss 26.3934 chose_rate 0.0625\n","Validation Accuracy = 0.8850 Max_Accuracy = 0.8950\n","Validation F1score = 0.8709 Max_f1score = 0.8829\n","Epoch 2.0730544384095526 time 3.7235164642333984s Step 1500 lambda 0.1853 lamb2 0.0000 rate 0.0100 C_loss 0.3916 G_loss -0.1397 D_loss 0.1397 SNTG_loss 24.6457 chose_rate 0.5000\n","Validation Accuracy = 0.8675 Max_Accuracy = 0.8950\n","Validation F1score = 0.8479 Max_f1score = 0.8829\n","Epoch 2.4185635114778115 time 3.1220366954803467s Step 1750 lambda 0.2153 lamb2 0.0000 rate 0.0100 C_loss 0.2737 G_loss nan D_loss nan SNTG_loss 26.9235 chose_rate 0.0000\n","Validation Accuracy = 0.8800 Max_Accuracy = 0.8950\n","Validation F1score = 0.8646 Max_f1score = 0.8829\n","Epoch 2.76407258454607 time 3.106215715408325s Step 2000 lambda 0.2449 lamb2 0.0000 rate 0.0100 C_loss 0.4663 G_loss -0.1181 D_loss 0.1181 SNTG_loss 26.3872 chose_rate 0.1562\n","Validation Accuracy = 0.8650 Max_Accuracy = 0.8950\n","Validation F1score = 0.8453 Max_f1score = 0.8829\n","Epoch 3.1095816576143287 time 4.4018003940582275s Step 2250 lambda 0.2741 lamb2 0.0000 rate 0.0100 C_loss 0.2942 G_loss nan D_loss nan SNTG_loss 27.7172 chose_rate 0.0000\n","Validation Accuracy = 0.8800 Max_Accuracy = 0.8950\n","Validation F1score = 0.8642 Max_f1score = 0.8829\n","Epoch 3.4550907306825875 time 3.1385586261749268s Step 2500 lambda 0.3027 lamb2 0.0000 rate 0.0100 C_loss 0.2643 G_loss -0.0939 D_loss 0.0939 SNTG_loss 23.6969 chose_rate 0.2188\n","Validation Accuracy = 0.8650 Max_Accuracy = 0.8950\n","Validation F1score = 0.8453 Max_f1score = 0.8829\n","Epoch 3.8005998037508464 time 3.575554370880127s Step 2750 lambda 0.3308 lamb2 0.0000 rate 0.0100 C_loss 0.1990 G_loss -0.1234 D_loss 0.1234 SNTG_loss 26.3651 chose_rate 0.0625\n","Validation Accuracy = 0.8650 Max_Accuracy = 0.8950\n","Validation F1score = 0.8440 Max_f1score = 0.8829\n","Epoch 4.146108876819105 time 3.1464498043060303s Step 3000 lambda 0.3584 lamb2 0.0000 rate 0.0100 C_loss 0.3341 G_loss -0.1225 D_loss 0.1225 SNTG_loss 25.2636 chose_rate 0.1250\n","Validation Accuracy = 0.8575 Max_Accuracy = 0.8950\n","Validation F1score = 0.8341 Max_f1score = 0.8829\n","Epoch 4.491617949887364 time 3.0806729793548584s Step 3250 lambda 0.3853 lamb2 0.0000 rate 0.0100 C_loss 0.3333 G_loss nan D_loss nan SNTG_loss 24.9841 chose_rate 0.0000\n","Validation Accuracy = 0.8325 Max_Accuracy = 0.8950\n","Validation F1score = 0.7983 Max_f1score = 0.8829\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/CAT/train_r.py\", line 272, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.9/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/MyDrive/CAT/train_r.py\", line 184, in main\n","    summary,_,closs,gloss,dloss,sn_loss, chose_rate_=sess.run([merged,optimizer,model.loss,model.G_loss,model.D_loss,model.sntg_loss, model.chose_rate], feed_dict={x_s: batch_xs,x_t: Tbatch_xs,decay_learning_rate:rate,adlamb:lamb,y: batch_ys,yt:Tbatch_ys,sntglamb:lamb2})\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 968, in run\n","    result = self._run(None, fetches, feed_dict, options_ptr,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1191, in _run\n","    results = self._do_run(handle, final_targets, final_fetches,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1371, in _do_run\n","    return self._do_call(_run_fn, feeds, fetches, targets, options,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1378, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1361, in _run_fn\n","    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/client/session.py\", line 1454, in _call_tf_sessionrun\n","    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"dOqJ8l67Pcnn"},"id":"dOqJ8l67Pcnn","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":66.111703,"end_time":"2022-08-23T17:40:55.963410","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-08-23T17:39:49.851707","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}