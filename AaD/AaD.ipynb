{"cells":[{"cell_type":"markdown","metadata":{"id":"f260223a"},"source":["<a id=\"section-one\"></a>\n","## 1 Import Libraries and download data"],"id":"f260223a"},{"cell_type":"markdown","metadata":{"id":"dd9d1294"},"source":["<a id=\"define-device\"></a>\n","### 1.2 Define device"],"id":"dd9d1294"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16325,"status":"ok","timestamp":1682474510637,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"},"user_tz":240},"id":"FqEDEQQJpwtB","outputId":"e18ef225-fa71-45c2-dda1-d42524bf390b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"FqEDEQQJpwtB"},{"cell_type":"markdown","source":["#OE 2 unbalanced labels"],"metadata":{"id":"dgKhIfA6koN3"},"id":"dgKhIfA6koN3"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,1)\n","\n","  return data\n","\n","\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=1\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=1\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=1\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:1045]\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:300]\n","frames = [Data_0, Data_2]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:772]\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:200]\n","frames = [Data_0, Data_2]\n","Final_Data_S2 = pd.concat(frames)\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[200:,:]\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[486:,:]\n","Target_test = Final_Data_S2.iloc[:486,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/AaD/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/AaD/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/AaD/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/AaD/data/Target_test.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaAL6_V_kn1J","executionInfo":{"status":"ok","timestamp":1682476278921,"user_tz":240,"elapsed":5227,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"5c18fd9c-262e-4064-f5ee-6dfefcb92e66"},"id":"oaAL6_V_kn1J","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n"]}]},{"cell_type":"markdown","source":["#OE 3 unbalanced labels"],"metadata":{"id":"H5kJaPJNi3uc"},"id":"H5kJaPJNi3uc"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,2)\n","\n","  return data\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=2\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=2\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=2\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=2\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:1045]\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:300]\n","Data_3 = Final_Data_S1[Final_Data_S1.labels == 2].iloc[:300]\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:772]\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:200]\n","Data_3 = Final_Data_S2[Final_Data_S2.labels == 2].iloc[:200]\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S2 = pd.concat(frames)\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[200:,:]\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[586:,:]\n","Target_test = Final_Data_S2.iloc[:586,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/AaD/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/AaD/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/AaD/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/AaD/data/Target_test.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6s34COBi3MM","executionInfo":{"status":"ok","timestamp":1682476202261,"user_tz":240,"elapsed":3602,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"f7f8ba78-7ef2-4e4c-ee35-c61b35653fe0"},"id":"Y6s34COBi3MM","execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n"]}]},{"cell_type":"markdown","source":["#OE balanced 2 labels"],"metadata":{"id":"iHUKkTdKkJP2"},"id":"iHUKkTdKkJP2"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,1)\n","\n","  return data\n","\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=1\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=1\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=1\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[500:,:]\n","Source_test = Final_Data_S1.iloc[:500,:]\n","\n","Target_train = Final_Data_S2.iloc[772:,:]\n","Target_test = Final_Data_S2.iloc[:772,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/AaD/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/AaD/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/AaD/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/AaD/data/Target_test.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qm7aAMUikGkX","executionInfo":{"status":"ok","timestamp":1682476418191,"user_tz":240,"elapsed":3786,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"166c0844-890c-4c1a-afe2-7fcd0e4f3f9d"},"id":"qm7aAMUikGkX","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"t_6Ru51m_deH"},"source":["#OE 3 labels balanced"],"id":"t_6Ru51m_deH"},{"cell_type":"code","execution_count":25,"metadata":{"id":"La67l8Ng-xmm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682475809908,"user_tz":240,"elapsed":4429,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"fca71fb8-47a9-4460-bf40-2f6f258835aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(2021)\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,2)\n","\n","  return data\n","\n","Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")\n","\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=2\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=2\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE \n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=2\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([0.0])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([1.0])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=2\n","\n","labels_S1 = Final_Data_S1.labels\n","labels_S2 = Final_Data_S2.labels\n","Data_S1 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n","Data_S2 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=9)\n","principalComponents_S1 = pca.fit_transform(Data_S1)\n","pca = PCA(n_components=9)\n","principalComponents_S2 = pca.fit_transform(Data_S2)\n","\n","sm = SMOTE(random_state=2)\n","principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n","principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n","\n","Final_Data_S1 = pd.DataFrame(principalComponents_S1)\n","Final_Data_S2 = pd.DataFrame(principalComponents_S2)\n","\n","Final_Data_S1['labels'] = labels_S1\n","Final_Data_S2['labels'] = labels_S2\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[500:,:]\n","Source_test = Final_Data_S1.iloc[:500,:]\n","\n","Target_train = Final_Data_S2.iloc[1158:,:]\n","Target_test = Final_Data_S2.iloc[:1158,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/AaD/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/AaD/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/AaD/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/AaD/data/Target_test.csv', index=False)"],"id":"La67l8Ng-xmm"},{"cell_type":"markdown","metadata":{"id":"aW1uEd59_iOv"},"source":["#Load Data AR: 3 Activities"],"id":"aW1uEd59_iOv"},{"cell_type":"code","execution_count":18,"metadata":{"id":"wyaalwUr-65K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682475453292,"user_tz":240,"elapsed":6687,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"1898b7fd-6f50-4b46-cf59-29529f154717"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (3.1.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn) (1.10.1)\n"]}],"source":["import pandas as pd \n","import numpy as np\n","np.random.seed(2021)\n","\n","!wget http://casas.wsu.edu/datasets/hh101.zip\n","!wget http://casas.wsu.edu/datasets/hh105.zip\n","!unzip '/content/hh105.zip'\n","!unzip /content/hh101.zip\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,2)\n","  return data\n","\n","\n","!pip install imbalanced-learn\n","from imblearn.over_sampling import SMOTE\n","\n","Final_Data_S1 = pd.read_csv(\"/content/hh101/hh101.ann.features.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/hh105/hh105.ann.features.csv\")\n","Final_Data_S1.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","Final_Data_S2.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","\n","Final_Data_S1 = Final_Data_S1.drop(['lastSensorEventHours', 'lastSensorEventSeconds', 'lastSensorDayOfWeek','lastSensorID'], axis= 1)\n","Final_Data_S2 = Final_Data_S2.drop(['lastSensorEventHours', 'lastSensorEventSeconds','lastSensorDayOfWeek', 'lastSensorID'], axis= 1)\n","\n","Final_Data_S1 = Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Breakfast',  'Watch_TV', 'Toilet' ])]\n","Final_Data_S2 = Final_Data_S2[Final_Data_S2.labels.isin([ 'Cook_Breakfast',  'Watch_TV', 'Toilet' ])]\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Toilet'])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Breakfast'])].index,'labels']=2\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Toilet'])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Breakfast'])].index,'labels']=2\n","\n","\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:4000]#2000#4000\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:2000]#2000\n","Data_3 = Final_Data_S1[Final_Data_S1.labels == 2].iloc[:2000]#2000\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:2000]#1000#2000\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:1000]#1000\n","Data_3 = Final_Data_S2[Final_Data_S2.labels == 2].iloc[:1000]#1000\n","frames = [Data_0, Data_2, Data_3]\n","Final_Data_S2 = pd.concat(frames)\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","\n","Source_train = Final_Data_S1.iloc[200:,:]#1000\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[2000:,:]#500\n","Target_test = Final_Data_S2.iloc[:2000,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/AaD/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/AaD/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/AaD/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/AaD/data/Target_test.csv', index=False)\n"],"id":"wyaalwUr-65K"},{"cell_type":"markdown","metadata":{"id":"hRCYevEuAB4A"},"source":["#Load Data AR: 5 Activities"],"id":"hRCYevEuAB4A"},{"cell_type":"code","execution_count":8,"metadata":{"id":"01hqvUJ9AGiO","executionInfo":{"status":"ok","timestamp":1682474945104,"user_tz":240,"elapsed":3673,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}}},"outputs":[],"source":["import pandas as pd \n","import numpy as np\n","import random\n","np.random.seed(2021)\n","!wget http://casas.wsu.edu/datasets/hh101.zip\n","!wget http://casas.wsu.edu/datasets/hh105.zip\n","!unzip '/content/hh105.zip'\n","!unzip /content/hh101.zip\n","\n","def poison_data(data, rate):\n","  indx = int(len(data)*rate)\n","  for i in range(indx):\n","    data.labels.iloc[i] = random.randint(0,4)\n","  return data\n","\n","Final_Data_S1 = pd.read_csv(\"/content/hh101/hh101.ann.features.csv\")\n","Final_Data_S2 = pd.read_csv(\"/content/hh105/hh105.ann.features.csv\")\n","Final_Data_S1.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","Final_Data_S2.rename(columns={\"activity\": \"labels\"}, inplace= True)\n","\n","Final_Data_S1 = Final_Data_S1.drop(['lastSensorEventHours', 'lastSensorEventSeconds', 'lastSensorDayOfWeek','lastSensorID'], axis= 1)\n","Final_Data_S2 = Final_Data_S2.drop(['lastSensorEventHours', 'lastSensorEventSeconds','lastSensorDayOfWeek', 'lastSensorID'], axis= 1)\n","\n","Final_Data_S1 = Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Dinner', 'Cook_Breakfast', 'Cook_Lunch', 'Watch_TV', 'Toilet' ])]\n","Final_Data_S2 = Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Dinner', 'Cook_Breakfast', 'Cook_Lunch', 'Watch_TV', 'Toilet' ])]\n","\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Lunch'])].index,'labels']=1\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Toilet'])].index,'labels']=2\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Breakfast'])].index,'labels']=3\n","Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin(['Cook_Dinner'])].index,'labels']=4\n","\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Watch_TV'])].index,'labels']=0\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Lunch'])].index,'labels']=1\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Toilet'])].index,'labels']=2\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Breakfast'])].index,'labels']=3\n","Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin(['Cook_Dinner'])].index,'labels']=4\n","\n","Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:4000]#2000#4000\n","Data_1 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:4000]#4000\n","Data_2 = Final_Data_S1[Final_Data_S1.labels == 2].iloc[:2000]#2000\n","Data_3 = Final_Data_S1[Final_Data_S1.labels == 3].iloc[:4000]#4000\n","Data_4 = Final_Data_S1[Final_Data_S1.labels == 4].iloc[:2000]#\n","frames = [Data_0, Data_1, Data_2, Data_3, Data_4]\n","Final_Data_S1 = pd.concat(frames)\n","\n","Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:2000]#1000#2000\n","Data_1 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:2000]#2000\n","Data_2 = Final_Data_S2[Final_Data_S2.labels == 2].iloc[:1000]#\n","Data_3 = Final_Data_S2[Final_Data_S2.labels == 3].iloc[:2000]#2000\n","Data_4 = Final_Data_S2[Final_Data_S2.labels == 4].iloc[:1000]#\n","frames = [Data_0, Data_1, Data_2, Data_3, Data_4]\n","Final_Data_S2 = pd.concat(frames)\n","\n","\n","Final_Data_S1 = Final_Data_S1.sample(frac = 1)\n","Final_Data_S2 = Final_Data_S2.sample(frac = 1)\n","\n","Source_train = Final_Data_S1.iloc[200:,:]#1000#\n","Source_test = Final_Data_S1.iloc[:200,:]\n","\n","Target_train = Final_Data_S2.iloc[1500:,:]#500#\n","Target_test = Final_Data_S2.iloc[:1500,:]\n","\n","#Source_train = poison_data(Source_train, 0.1)\n","#Target_train = poison_data(Target_train, 0.1)\n","\n","Source_train.to_csv('/content/drive/MyDrive/AaD/data/Source_train.csv', index=False)\n","Source_test.to_csv('/content/drive/MyDrive/AaD/data/Source_test.csv', index=False)\n","Target_train.to_csv('/content/drive/MyDrive/AaD/data/Target_train.csv', index=False)\n","Target_test.to_csv('/content/drive/MyDrive/AaD/data/Target_test.csv', index=False)"],"id":"01hqvUJ9AGiO"},{"cell_type":"code","execution_count":41,"metadata":{"id":"rB2HRmYbE8G3","executionInfo":{"status":"ok","timestamp":1682476422944,"user_tz":240,"elapsed":195,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}}},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/AaD')"],"id":"rB2HRmYbE8G3"},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HLpsyW2_Pb4","executionInfo":{"status":"ok","timestamp":1682476440622,"user_tz":240,"elapsed":17517,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"ac1ba2a1-1e0d-43cb-b56a-347f73b21dc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:25/250; Accuracy = 79.01%\n","80.16 77.87\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:50/250; Accuracy = 78.93%\n","73.28 84.58\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:75/250; Accuracy = 79.33%\n","73.28 85.38\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:100/250; Accuracy = 79.54%\n","74.49 84.58\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:125/250; Accuracy = 80.13%\n","74.09 86.17\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:150/250; Accuracy = 80.33%\n","74.09 86.56\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:175/250; Accuracy = 80.52%\n","74.09 86.96\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:200/250; Accuracy = 79.93%\n","74.09 85.77\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:225/250; Accuracy = 80.33%\n","74.09 86.56\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T, Iter:250/250; Accuracy = 80.72%\n","74.09 87.35\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Task: T; Accuracy on target = 86.92%\n","84.95 88.89\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","\n","Training: val, Task: TV, Accuracy = 86.92%\n","84.95 88.89\n"]}],"source":["!python src_pretrain.py"],"id":"7HLpsyW2_Pb4"},{"cell_type":"code","source":["!python tar_adaptation.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yRO8eZw8BUM","executionInfo":{"status":"ok","timestamp":1682476471893,"user_tz":240,"elapsed":31283,"user":{"displayName":"Jawher Dridi","userId":"09677130424740496435"}},"outputId":"e573d754-c749-4e1a-e154-621342c31d54"},"id":"-yRO8eZw8BUM","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/AaD/tar_adaptation.py:150: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_out = nn.Softmax()(outputs)\n","Task: TV, Iter:260/1300;  Acc on target: 87.30, Fscore on target: 87.06\n","T: 83.5 91.11\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/AaD/tar_adaptation.py:150: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_out = nn.Softmax()(outputs)\n","Task: TV, Iter:520/1300;  Acc on target: 86.11, Fscore on target: 85.61\n","T: 78.88 93.33\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/AaD/tar_adaptation.py:150: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_out = nn.Softmax()(outputs)\n","Task: TV, Iter:780/1300;  Acc on target: 86.42, Fscore on target: 85.85\n","T: 78.4 94.44\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/AaD/tar_adaptation.py:150: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_out = nn.Softmax()(outputs)\n","Task: TV, Iter:1040/1300;  Acc on target: 86.44, Fscore on target: 85.85\n","T: 78.16 94.72\n","\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/AaD/tar_adaptation.py:150: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  softmax_out = nn.Softmax()(outputs)\n","Task: TV, Iter:1300/1300;  Acc on target: 86.00, Fscore on target: 85.47\n","T: 78.4 93.61\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QPTnwNXh_Ftb"},"id":"QPTnwNXh_Ftb","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":66.111703,"end_time":"2022-08-23T17:40:55.963410","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-08-23T17:39:49.851707","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}